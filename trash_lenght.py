text = """
Mettre son modÃ¨le ML en production, attendre sans jamais le rÃ©entraÃ®ner, voir que pour faire des prÃ©visions de stock, il a en output des lettres ğŸ¤¡



L'IA est pas mal Ã  la mode, on fait nos petites infÃ©rences, on met le tout dans un docker et puis c'est parti !
Au dÃ©but tout se passe bien, ensuite le modÃ¨le se dÃ©grade sauf qu'on n'avait rien prÃ©vu et d'ailleurs on ne l'avait mÃªme pas monitorÃ©....


Comment aurait-on pu faire pour gÃ©rer Ã§a ?

Pas le choix, on doit tester en production, mais avec une bonne stratÃ©gie de dÃ©ploiement ğŸ‘‡
âš«Shadow Deployment : Deux modÃ¨les en simultanÃ©, avec un champion qui est exposÃ© Ã  l'audience et un challenger qui lui ne l'est pas, celui qui a le meilleur score prend la place de champion
ğŸ“ŠA/B Testing : Cette fois nos deux modÃ¨les sont exposÃ©s au trafic mais pas au mÃªme, il faut impÃ©rativement que les Ã©chantillons du champion et du challenger soient distincts et alÃ©atoires
ğŸ¥Canary release : Ressemble Ã  l'A/B test sauf qu'il n'y a pas d'alÃ©atoire et que le challenger est obligatoirement exposÃ© Ã  une plus petite partie du trafic, c'est une sÃ©curitÃ© pour Ã©viter de finir comme CrowdStrike



Dans l'industrie la mÃ©thode la plus utilisÃ©e est l'A/B testing pour le moment mais la mÃ©thode Bandit est prometteuse. Sinon toi tu faisais comment ? Dis-moi tout en commentaire !
"""

lenght_text = len(text)

print(lenght_text)
